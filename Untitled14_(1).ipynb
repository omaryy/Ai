{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14_(1).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omaryy/Ai/blob/main/Untitled14_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZaMcNcDwisZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "!pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "import math, re, os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        " \n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "\n",
        "! kaggle competitions download -c tpu-getting-started\n",
        "! unzip tpu-getting-started.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "miV2-7bNf-Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() \n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n"
      ],
      "metadata": {
        "id": "sEsGTMReXiKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = [192, 192]\n",
        "BATCH_SIZE = 16 \n",
        "EPOCHS = 1\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "MODEL_NAME = ['EfficientNetB7']\n",
        "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 10個\n",
        "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', \n",
        "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         \n",
        "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           \n",
        "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      \n",
        "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    \n",
        "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            \n",
        "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             \n",
        "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            \n",
        "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        \n",
        "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']     "
      ],
      "metadata": {
        "id": "_1baIYU_Xygj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gcs_path =  f'/content/tfrecords-jpeg-{IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}'\n",
        " \n",
        "\n",
        "training_filenames = tf.io.gfile.glob(gcs_path + '/train/*.tfrec')\n",
        "validation_filenames = tf.io.gfile.glob(gcs_path + '/val/*.tfrec')\n",
        "test_filenames = tf.io.gfile.glob(gcs_path + '/test/*.tfrec')  \n",
        "\n",
        "     \n"
      ],
      "metadata": {
        "id": "8APDQhNOxucK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # 標準化\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    return image\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    label = tf.cast(example['class'], tf.int32)\n",
        "    return image, label\n",
        "\n",
        "def read_unlabeled_tfrecord(example):\n",
        "    UNLABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "        \"id\": tf.io.FixedLenFeature([], tf.string), \n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    idnum = example['id']\n",
        "    return image, idnum\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # 增加運算速度\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "    dataset = dataset.with_options(ignore_order) \n",
        "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
        "    # returns (image, label) 或是 (image, id)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "YiM_oT96yWRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 2020  #數據增強引入隨機性\n",
        "\n",
        "#隨機遮蔽\n",
        "def random_blockout(img, sl=0.1, sh=0.2, rl=0.4):\n",
        "    p=random.random()\n",
        "    if p>=0.25:\n",
        "        w, h, c = IMAGE_SIZE[0], IMAGE_SIZE[1], 3\n",
        "        origin_area = tf.cast(h*w, tf.float32)\n",
        "\n",
        "        e_size_l = tf.cast(tf.round(tf.sqrt(origin_area * sl * rl)), tf.int32)\n",
        "        e_size_h = tf.cast(tf.round(tf.sqrt(origin_area * sh / rl)), tf.int32)\n",
        "\n",
        "        e_height_h = tf.minimum(e_size_h, h)\n",
        "        e_width_h = tf.minimum(e_size_h, w)\n",
        "\n",
        "        erase_height = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_height_h, dtype=tf.int32)\n",
        "        erase_width = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_width_h, dtype=tf.int32)\n",
        "\n",
        "        erase_area = tf.zeros(shape=[erase_height, erase_width, c])\n",
        "        erase_area = tf.cast(erase_area, tf.uint8)\n",
        "\n",
        "        pad_h = h - erase_height\n",
        "        pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n",
        "        pad_bottom = pad_h - pad_top\n",
        "\n",
        "        pad_w = w - erase_width\n",
        "        pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n",
        "        pad_right = pad_w - pad_left\n",
        "\n",
        "        erase_mask = tf.pad([erase_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n",
        "        erase_mask = tf.squeeze(erase_mask, axis=0)\n",
        "        erased_img = tf.multiply(tf.cast(img,tf.float32), tf.cast(erase_mask, tf.float32))\n",
        "\n",
        "        return tf.cast(erased_img, img.dtype)\n",
        "    else:\n",
        "        return tf.cast(img, img.dtype)\n",
        "\n",
        "    \n",
        "def data_augment_v2(image, label):\n",
        "    \n",
        "    flag = random.randint(1,3)\n",
        "    coef_1 = random.randint(60, 80) * 0.01\n",
        "    coef_2 = random.randint(60, 80) * 0.01\n",
        "    \n",
        "    if flag == 1:\n",
        "        image = tf.image.random_flip_left_right(image, seed=SEED)\n",
        "    elif flag == 2:\n",
        "        image = tf.image.random_flip_up_down(image, seed=SEED)\n",
        "    else:\n",
        "        image = tf.image.random_crop(image, [int(IMAGE_SIZE[0]*coef_1), int(IMAGE_SIZE[0]*coef_2), 3],seed=SEED)\n",
        "        \n",
        "    image = random_blockout(image)\n",
        "    \n",
        "    return image, label \n",
        "    "
      ],
      "metadata": {
        "id": "WjO6XozJZ8ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def data_augment_v3(image, label):\n",
        "    seed = 100\n",
        "    \n",
        "    image = tf.image.resize(image, [720, 720])\n",
        "    image = tf.image.random_crop(image, [512, 512, 3], seed = seed)\n",
        "\n",
        "    image = tf.image.random_brightness(image, 0.6, seed = seed)\n",
        "    \n",
        "    image = tf.image.random_saturation(image, 3, 5, seed = seed)\n",
        "        \n",
        "    image = tf.image.random_contrast(image, 0.3, 0.5, seed = seed)\n",
        "    \n",
        "    image = tfa.image.mean_filter2d(image, filter_shape = 10)\n",
        "    \n",
        "    image = tf.image.random_flip_left_right(image, seed = seed)\n",
        "    image = tf.image.random_flip_up_down(image, seed = seed)\n",
        "    \n",
        "    return image, label\n",
        "    "
      ],
      "metadata": {
        "id": "qd3IPlfiaDgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    return image, label   \n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(training_filenames, labeled=True)\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO) # 引用數據增強\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(AUTO) \n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(ordered=False):\n",
        "    dataset = load_dataset(validation_filenames, labeled=True, ordered=ordered)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(test_filenames, labeled=False, ordered=ordered)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "num_training_images = count_data_items(training_filenames)\n",
        "num_validation_images = count_data_items(validation_filenames)\n",
        "num_test_images = count_data_items(test_filenames)\n",
        "print('{} train, {} val, {} test'.format(num_training_images, num_validation_images, num_test_images))\n"
      ],
      "metadata": {
        "id": "nI7pzxvuaYKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy.num_replicas_in_sync\n",
        "batch_size = BATCH_SIZE * strategy.num_replicas_in_sync \n",
        "\n",
        "ds_train = get_training_dataset()\n",
        "ds_valid = get_validation_dataset()\n",
        "ds_test = get_test_dataset()\n",
        "\n",
        "print(\"Train:\", ds_train)\n",
        "print (\"Val:\", ds_valid)\n",
        "print(\"Test:\", ds_test)\n"
      ],
      "metadata": {
        "id": "5hI6VXpga9La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(threshold=15, linewidth=80)\n",
        "\n",
        "print(\"Training data shapes:\")\n",
        "for image, label in ds_train.take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape) \n",
        "print(\"Training data label examples:\", label.numpy())\n"
      ],
      "metadata": {
        "id": "2yrYez_9bBiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test data shapes:\")\n",
        "for image, idnum in ds_test.take(3):\n",
        "    print(image.numpy().shape, idnum.numpy().shape) \n",
        "print(\"Test data IDs:\", idnum.numpy().astype('U'))"
      ],
      "metadata": {
        "id": "vsk8iHUxbOxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import gc\n",
        "gc.enable()\n",
        "\n",
        "def get_training_dataset_raw():\n",
        "    dataset = load_dataset(training_filenames, labeled = True, ordered = False)\n",
        "    return dataset\n",
        "\n",
        "raw_training_dataset = get_training_dataset_raw()\n",
        "\n",
        "label_counter = Counter()\n",
        "for images, labels in raw_training_dataset:\n",
        "    label_counter.update([labels.numpy()])\n",
        "\n",
        "del raw_training_dataset    \n",
        "\n",
        "TARGET_NUM_PER_CLASS = 122 \n",
        "\n",
        "def get_weight_for_class(class_id):\n",
        "    counting = label_counter[class_id]\n",
        "    weight = TARGET_NUM_PER_CLASS / counting\n",
        "    return weight\n",
        "\n",
        "weight_per_class = {class_id: get_weight_for_class(class_id) for class_id in range(104)}\n"
      ],
      "metadata": {
        "id": "woP9KfT5efiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import cm\n",
        "data = pd.DataFrame.from_dict(weight_per_class, orient='index', columns=['class_weight'])\n",
        "plt.figure(figsize=(30, 9))\n",
        "\n",
        "#barplot color based on value\n",
        "bplot = sns.barplot(x=data.index, y='class_weight', data=data, palette= cm.Blues(data['class_weight']*0.15));\n",
        "for p in bplot.patches:\n",
        "    bplot.annotate(format(p.get_height(), '.1f'), \n",
        "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "                    ha = 'center', va = 'center', \n",
        "                    xytext = (0, 9), \n",
        "                    textcoords = 'offset points')\n",
        "plt.xlabel(\"Class\", size=14)\n",
        "plt.ylabel(\"Class weight (inverse of %)\", size=14)\n"
      ],
      "metadata": {
        "id": "frLfo20MeqcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def batch_to_numpy_images_and_labels(data):\n",
        "    images, labels = data\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "    if numpy_labels.dtype == object: # binary string in this case,these are image ID strings\n",
        "        numpy_labels = [None for _ in enumerate(numpy_images)]\n",
        "        # If no labels, only image IDs, return None for labels (this is the case for test data)\n",
        "    return numpy_images, numpy_labels\n",
        "\n",
        "def title_from_label_and_target(label, correct_label):\n",
        "    if correct_label is None:\n",
        "        return CLASSES[label], True\n",
        "    correct = (label == correct_label)\n",
        "    return \"{} [{}{}{}]\".format(CLASSES[label], \n",
        "                                'OK' if correct else 'NO', \n",
        "                                u\"\\u2192\" if not correct else '',\n",
        "                                CLASSES[correct_label] if not correct else ''), correct\n",
        "\n",
        "def display_one_flower(image, title, subplot, red=False, titlesize=16):\n",
        "    plt.subplot(*subplot)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "    if len(title) > 0:\n",
        "        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n",
        "    return (subplot[0], subplot[1], subplot[2]+1)\n",
        "    \n",
        "def display_batch_of_images(databatch, predictions=None, display_mismatches_only=False):\n",
        "    \"\"\"This will work with:\n",
        "    display_batch_of_images(images)\n",
        "    display_batch_of_images(images, predictions)\n",
        "    display_batch_of_images((images, labels))\n",
        "    display_batch_of_images((images, labels), predictions)\n",
        "    \"\"\"\n",
        "    # data\n",
        "    images, labels = batch_to_numpy_images_and_labels(databatch)\n",
        "    if labels is None:\n",
        "        labels = [None for _ in enumerate(images)]\n",
        "        \n",
        "    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n",
        "    rows = int(math.sqrt(len(images)))\n",
        "    cols = len(images)//rows\n",
        "        \n",
        "    # size and spacing\n",
        "    FIGSIZE = 13.0\n",
        "    SPACING = 0.1\n",
        "    subplot=(rows,cols,1)\n",
        "    if rows < cols:\n",
        "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n",
        "    else:\n",
        "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n",
        "    \n",
        "    # display\n",
        "    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n",
        "        title = '' if label is None else CLASSES[label]\n",
        "        correct = True\n",
        "        if predictions is not None:\n",
        "            title, correct = title_from_label_and_target(predictions[i], label)\n",
        "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n",
        "        if display_mismatches_only:\n",
        "            if predictions[i] != label:\n",
        "                subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n",
        "        else:        \n",
        "            subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n",
        "    \n",
        "    #layout\n",
        "    plt.tight_layout()\n",
        "    if label is None and predictions is None:\n",
        "        plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    else:\n",
        "        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    if subplot%10==1: # set up the subplots on the first call\n",
        "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor('#F8F8F8')\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model '+ title)\n",
        "    ax.set_ylabel(title)\n",
        "    #ax.set_ylim(0.28,1.05)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train', 'valid.'])\n",
        "\n",
        "def display_training_curves_v2(training, validation, learning_rate_list, title, subplot):\n",
        "    if subplot%10==1: # set up the subplots on the first call\n",
        "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor('#F8F8F8')\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model '+ title)\n",
        "    ax.set_ylabel(title, color='b')\n",
        "    #ax.set_ylim(0.28,1.05)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train', 'valid.', 'learning rate'])        \n",
        "    \n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(learning_rate_list, 'g-')\n",
        "    ax2.set_ylabel('learning rate', color='g')\n",
        "ds_iter = iter(ds_train.unbatch().batch(20))\n",
        "one_batch = next(ds_iter)\n",
        "display_batch_of_images(one_batch)\n"
      ],
      "metadata": {
        "id": "aVL4yeV0fWS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('pre-train list:\\n', ', '.join(tf.keras.applications.__dir__()))\n"
      ],
      "metadata": {
        "id": "PwKRR3-6fpYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_efficientnet = True \n",
        "if use_efficientnet:\n",
        "    !pip install -q efficientnet\n",
        "    from efficientnet.tfkeras import EfficientNetB7"
      ],
      "metadata": {
        "id": "YKt2GX40ht0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#string as code\n",
        "# model_command = f'tf.keras.applications.{MODEL_NAME[0]}'\n",
        "# pretrained_model = eval(model_command)\n",
        "\n",
        "with strategy.scope():\n",
        "    #pretrained_model = tf.keras.applications.DenseNet201\n",
        "    #pretrained_model = tf.keras.applications.NASNetMobile\n",
        "    #pretrained_model = tf.keras.applications.ResNet101V2\n",
        "    #pretrained_model = tf.keras.applications.MobileNetV2\n",
        "    #pretrained_model = EfficientNetB7\n",
        "\n",
        "    pretrained_model = EfficientNetB7(include_top=False, weights='imagenet', input_shape=[*IMAGE_SIZE, 3])\n",
        "    pretrained_model.trainable = True\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        pretrained_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(), \n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "        ],\n",
        "        name= MODEL_NAME[0]\n",
        "    )\n",
        "model.compile(\n",
        "    optimizer='nadam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy'],\n",
        ")\n",
        "model.summary()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "3wxxXc4riCVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = f\"Flowers-Classification-{model.name}.h5\"\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "oZ2ovJk-iVnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "def exponential_lr(epoch, start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005 * strategy.num_replicas_in_sync,\n",
        "                    rampup_epochs = 5, sustain_epochs = 0,\n",
        "                    exp_decay = 0.75): \n",
        "\n",
        "    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n",
        "        if epoch < rampup_epochs:\n",
        "            lr = ((max_lr - start_lr) / rampup_epochs * epoch + start_lr)\n",
        "        elif epoch < rampup_epochs + sustain_epochs:\n",
        "            lr = max_lr\n",
        "        else:\n",
        "            lr = ((max_lr - min_lr) * exp_decay**(epoch - rampup_epochs - sustain_epochs) + min_lr)\n",
        "        return lr\n",
        "    \n",
        "    return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n",
        "\n",
        "\n",
        "rng = [i for i in range(EPOCHS)]\n",
        "y = [exponential_lr(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate curve: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "id": "HiR2qv-4iXU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_valid,\n",
        "    epochs=1,\n",
        "    steps_per_epoch=num_training_images / batch_size,\n",
        "    callbacks=[lr_callback, checkpoint], \n",
        "    class_weight = weight_per_class\n",
        ")\n"
      ],
      "metadata": {
        "id": "9D92bN5niekx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transfer learning \n"
      ],
      "metadata": {
        "id": "W5N4iSayBJU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_training_curves(training, validation, lr, title, subplot):\n",
        "    if subplot%10==1: # set up the subplots on the first call\n",
        "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor('#F8F8F8')\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model '+ title)\n",
        "    ax.set_ylabel(title)\n",
        "    #ax.set_ylim(0.28,1.05)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train', 'valid.'])\n",
        "display_training_curves( \n",
        "    history.history['loss'],\n",
        "    history.history['val_loss'],\n",
        "    history.history['lr'],\n",
        "    'loss',\n",
        "    211,\n",
        ")\n",
        "\n",
        "display_training_curves(\n",
        "    history.history['sparse_categorical_accuracy'],\n",
        "    history.history['val_sparse_categorical_accuracy'],\n",
        "    history.history['lr'],\n",
        "    'accuracy',\n",
        "    212,\n",
        ")\n",
        "zoom_after = 15\n",
        "display_training_curves(\n",
        "    history.history['loss'][zoom_after:],\n",
        "    history.history['val_loss'][zoom_after:],\n",
        "    history.history['lr'],\n",
        "    'loss',\n",
        "    211,\n",
        ")\n",
        "\n",
        "display_training_curves(\n",
        "    history.history['sparse_categorical_accuracy'][zoom_after:],\n",
        "    history.history['val_sparse_categorical_accuracy'][zoom_after:],\n",
        "    history.history['lr'],\n",
        "    'accuracy',\n",
        "    212,\n",
        ")\n",
        " \n",
        "model.load_weights(checkpoint_filepath)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "MYdPGeRJii45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ensemble\n",
        "if len(MODEL_NAME)>1:\n",
        "    using_ensemble_models = True\n",
        "else:\n",
        "    using_ensemble_models = False\n",
        "def get_pretrained_model(model_name, image_dataset_weights, trainable=True):\n",
        "    pretrained_model= model_name(\n",
        "        include_top=False ,\n",
        "        weights=image_dataset_weights,\n",
        "        input_shape=[*IMAGE_SIZE, 3]\n",
        "    )\n",
        "\n",
        "    pretrained_model.trainable = trainable\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "        pretrained_model, \n",
        "        tf.keras.layers.GlobalAveragePooling2D(), \n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    return model\n",
        "if using_ensemble_models:\n",
        "    with strategy.scope():\n",
        "        model_EB7 = get_pretrained_model(EfficientNetB7, 'noisy-student', trainable=True)\n",
        "\n",
        "    model_EB7.load_weights(f'../input/models/Flowers-Classification-{model.name}.h5')    \n",
        "if using_ensemble_models:\n",
        "    model_EB7.summary()\n",
        "if using_ensemble_models:\n",
        "    with strategy.scope():\n",
        "        model_D201 = get_pretrained_model(tf.keras.applications.DenseNet201, 'imagenet', trainable=True)\n",
        "\n",
        "    model_D201.load_weights('../input/models/Flowers-Classification-DenseNet201.h5')  \n",
        "if using_ensemble_models:\n",
        "    model_D201.summary()\n",
        "  \n"
      ],
      "metadata": {
        "id": "mqsqVRODsXqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "if using_ensemble_models:\n",
        "    cmdataset = get_validation_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n",
        "    images_ds = cmdataset.map(lambda image, label: image)\n",
        "    labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "    cm_correct_labels = next(iter(labels_ds.batch(num_validation_images))).numpy() # get everything as one batch\n",
        "\n",
        "    m1 = model_EB7.predict(images_ds)\n",
        "    m2 = model_D201.predict(images_ds)\n",
        "\n",
        "    scores = []\n",
        "    for alpha in np.linspace(0,1,100):\n",
        "        cm_probabilities = alpha*m1+(1-alpha)*m2\n",
        "        cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "        scores.append(f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro'))\n",
        "\n",
        "    print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n",
        "    print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)\n",
        "    plt.plot(scores)\n",
        "\n",
        "    best_alpha = np.argmax(scores)/100\n",
        "    cm_probabilities = best_alpha*m1+(1-best_alpha)*m2\n",
        "    cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "\n",
        "    #best_alpha = 0.35\n",
        "if using_ensemble_models:\n",
        "    print(best_alpha, max(scores))\n",
        "if using_ensemble_models:\n",
        "    test_ds = get_test_dataset(ordered=True)\n",
        "    #best_alpha = 0.35\n",
        "\n",
        "    print('Computing predictions...')\n",
        "    test_images_ds = test_ds.map(lambda image, idnum: image)\n",
        "    probabilities1 = model_EB7.predict(test_images_ds)\n",
        "    probabilities2 = model_D201.predict(test_images_ds)\n",
        "\n",
        "    probabilities = best_alpha * probabilities1 + (1 - best_alpha) * probabilities2\n",
        "\n",
        "    predictions = np.argmax(probabilities, axis=-1)\n",
        "    print(predictions)\n",
        "\n",
        "    print('Generating submission.csv file...')\n",
        "    # Get image ids from test set and convert to unicode\n",
        "    test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
        "    test_ids = next(iter(test_ids_ds.batch(num_test_images))).numpy().astype('U')\n",
        "\n",
        "    # Write the submission file\n",
        "    np.savetxt(\n",
        "        'submission.csv',\n",
        "        np.rec.fromarrays([test_ids, predictions]),\n",
        "        fmt=['%s', '%d'],\n",
        "        delimiter=',',\n",
        "        header='id,label',\n",
        "        comments='',\n",
        "    )\n",
        "\n",
        "    # Look at the first few predictions\n",
        "    !head submission.csv\n",
        "    "
      ],
      "metadata": {
        "id": "x6rJLnVsubWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "def display_confusion_matrix(cmat, score, precision, recall):\n",
        "    plt.figure(figsize=(25,25))\n",
        "    ax = plt.gca()\n",
        "    ax.matshow(cmat, cmap='Reds')\n",
        "    ax.set_xticks(range(len(CLASSES)))\n",
        "    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n",
        "    ax.set_yticks(range(len(CLASSES)))\n",
        "    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n",
        "    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "    titlestring = \"\"\n",
        "    if score is not None:\n",
        "        titlestring += 'f1 = {:.3f} '.format(score)\n",
        "    if precision is not None:\n",
        "        titlestring += '\\nprecision = {:.3f} '.format(precision)\n",
        "    if recall is not None:\n",
        "        titlestring += '\\nrecall = {:.3f} '.format(recall)\n",
        "    if len(titlestring) > 0:\n",
        "        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n",
        "    \n",
        "    if not using_ensemble_models:\n",
        "        print('Epoch with min loss and max accuracy:', np.argmin(history.history['val_loss']), np.argmax(history.history['val_sparse_categorical_accuracy']))\n",
        "        print('min loss and max accuracy:', round(min(history.history['val_loss']),2), round(max(history.history['val_sparse_categorical_accuracy']),2))\n",
        "\n",
        "    print(titlestring.replace('\\n', ''))\n",
        "    plt.show()\n",
        "    \n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    if subplot%10==1: \n",
        "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor('#F8F8F8')\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model '+ title)\n",
        "    ax.set_ylabel(title)\n",
        "    #ax.set_ylim(0.28,1.05)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train', 'valid.'])\n",
        "# Confusion Matrix\n",
        "cmdataset = get_validation_dataset(ordered=True)\n",
        "images_ds = cmdataset.map(lambda image, label: image)\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "\n",
        "cm_correct_labels = next(iter(labels_ds.batch(num_validation_images))).numpy()\n",
        "\n",
        "if using_ensemble_models:\n",
        "    print('using_ensemble_models')\n",
        "    probabilities1 = model_EB7.predict(images_ds)\n",
        "    probabilities2 = model_D201.predict(images_ds)\n",
        "    cm_probabilities = best_alpha * probabilities1 + (1 - best_alpha) * probabilities2\n",
        "else:\n",
        "    cm_probabilities = model.predict(images_ds)\n",
        "    \n",
        "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "\n",
        "labels = range(len(CLASSES))\n",
        "cmat = confusion_matrix(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        ")\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T\n",
        "cmat\n",
        "score = f1_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "\n",
        "precision = precision_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "\n",
        "recall = recall_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "\n",
        "display_confusion_matrix(cmat, score, precision, recall)"
      ],
      "metadata": {
        "id": "YfUG2EpPud1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_validation_dataset()\n",
        "dataset = dataset.unbatch().batch(20)\n",
        "batch = iter(dataset)\n",
        "images, labels = next(batch)\n",
        "if using_ensemble_models:\n",
        "    probabilities1 = model_EB7.predict(images)\n",
        "    probabilities2 = model_D201.predict(images)\n",
        "    probabilities = best_alpha * probabilities1 + (1 - best_alpha) * probabilities2\n",
        "else:\n",
        "    probabilities = model.predict(images)\n",
        "predictions = np.argmax(probabilities, axis=-1)\n",
        "display_batch_of_images((images, labels), predictions)\n"
      ],
      "metadata": {
        "id": "dm5PCi6Dud7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the validation data for testing the final model.\n",
        "mismatches = sum(cm_predictions!=cm_correct_labels)\n",
        "print('validation data上的錯誤: {} / {} ({:.2%})'.format(mismatches, num_validation_images, mismatches/num_validation_images))\n",
        "cmdataset = get_validation_dataset(ordered=True)\n",
        "images_ds = cmdataset.map(lambda image, label: image)\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "cm_correct_labels = next(iter(labels_ds.batch(num_validation_images))).numpy() # get everything as one batch\n",
        "\n",
        "mismatches_images, mismatches_predictions, mismatches_labels = [], [], []\n",
        "mismatches_dataset = tf.data.Dataset.from_tensors([])\n",
        "val_batch = iter(cmdataset.unbatch().batch(1))\n",
        "\n",
        "for image_index in range(num_validation_images):\n",
        "    batch = next(val_batch)\n",
        "    if cm_predictions[image_index] != cm_correct_labels[image_index]:\n",
        "        print('Predicted vs Correct labels: {}, {}'.format(cm_predictions[image_index], cm_correct_labels[image_index]))\n",
        "        #display_batch_of_images(batch, np.array([cm_predictions[image_index]]))\n",
        "        #mismatches_dataset = tf.data.Dataset.from_tensors(batch)\n",
        "        #mismatches_images.append(tf.data.Dataset.from_tensors(batch))\n",
        "        #mismatches_predictions.append(cm_predictions[image_index])\n",
        "        #mismatches_labels.append(cm_correct_labels[image_index])\n",
        "dataset = get_validation_dataset()\n",
        "dataset = dataset.unbatch().batch(20)\n",
        "batch = iter(dataset)\n",
        "images, labels = next(batch)\n",
        "for i in range(3):\n",
        "    display_batch_of_images((images, labels), predictions, display_mismatches_only=True)\n",
        "    images, labels = next(batch)\n",
        "one_batch = next(ds_iter)\n",
        "display_batch_of_images(one_batch)\n"
      ],
      "metadata": {
        "id": "9E5KQf5vuvhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test set \n",
        "using_tta = False\n",
        "tta_iterations = 3\n",
        "if using_tta:\n",
        "    def get_test_dataset(ordered=False):\n",
        "        dataset = load_dataset(test_filenames, labeled=False, ordered=ordered)\n",
        "        dataset = dataset.map(data_augment, num_parallel_calls=AUTO) #tuning4\n",
        "        #dataset = dataset.map(data_augment_v2, num_parallel_calls=AUTO)\n",
        "        #dataset = dataset.map(data_augment_v3, num_parallel_calls=AUTO)\n",
        "        dataset = dataset.batch(batch_size)\n",
        "        dataset = dataset.prefetch(AUTO)\n",
        "        return dataset\n",
        "def predict_tta(model, tta_iterations):\n",
        "    probs  = []\n",
        "    for i in range(tta_iterations):\n",
        "        print('TTA iteration ', i)\n",
        "        test_ds = get_test_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and ids, order matters.\n",
        "        test_images_ds = test_ds.map(lambda image, idnum: image)\n",
        "        \n",
        "        if using_ensemble_models:\n",
        "            print('using_ensemble_models')\n",
        "            probabilities1 = model_EB7.predict(test_images_ds)\n",
        "            probabilities2 = model_D201.predict(test_images_ds)\n",
        "            probabilities = best_alpha * probabilities1 + (1 - best_alpha) * probabilities2\n",
        "            probs.append(probabilities)\n",
        "        else:\n",
        "            probs.append(model.predict(test_images_ds,verbose=0))\n",
        "        \n",
        "    return probs\n",
        "test_ds = get_test_dataset(ordered=True)\n",
        "test_images_ds = test_ds.map(lambda image, idnum: image)\n",
        "\n",
        "if using_tta:\n",
        "    print('Predictions using TTA...')\n",
        "    probabilities = np.mean(predict_tta(model, tta_iterations), axis=0)\n",
        "else:\n",
        "    print('Predictions...')\n",
        "    probabilities = model.predict(test_images_ds)\n",
        "predictions = np.argmax(probabilities, axis=-1)\n",
        "print(predictions)\n",
        "print('using_ensemble_models:', using_ensemble_models)\n",
        "print('Generating submission.csv file...')\n",
        "\n",
        "# Get image ids from test set and convert to unicode\n",
        "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
        "test_ids = next(iter(test_ids_ds.batch(num_test_images))).numpy().astype('U')\n",
        "\n",
        "# Write the submission file\n",
        "np.savetxt(\n",
        "    'submission.csv',\n",
        "    np.rec.fromarrays([test_ids, predictions]),\n",
        "    fmt=['%s', '%d'],\n",
        "    delimiter=',',\n",
        "    header='id,label',\n",
        "    comments='',\n",
        ")\n",
        "\n",
        "# Look at the first few predictions\n",
        "!head submission.csv\n"
      ],
      "metadata": {
        "id": "cJoigJqhu-gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import vgg16\n",
        "from keras.models import Model\n",
        "import keras\n",
        "\n",
        "vgg = vgg16.VGG16(include_top=False, weights='imagenet', \n",
        "                                     input_shape=input_shape)\n",
        "\n",
        "output = vgg.layers[-1].output\n",
        "output = keras.layers.Flatten()(output)\n",
        "vgg_model = Model(vgg.input, output)\n",
        "\n",
        "vgg_model.trainable = False\n",
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "import pandas as pd\n",
        "pd.set_option('max_colwidth', -1)\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])  "
      ],
      "metadata": {
        "id": "IYhwRfxnWW2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-UaAWnZzYQ12"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}